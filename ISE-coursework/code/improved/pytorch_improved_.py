# -*- coding: utf-8 -*-
"""pytorch_improved_.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XRQobysGMEOLjWbjIQ5Z-QxmI_ad38Mw
"""

# Import necessary libraries
import pandas as pd
import numpy as np
import re
import os
import nltk
from nltk.stem import PorterStemmer, WordNetLemmatizer
from nltk.corpus import stopwords
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split, GridSearchCV, KFold
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import MultinomialNB
from imblearn.over_sampling import SMOTE
from collections import defaultdict

# Ensure nltk resources are available
nltk.download('stopwords')
nltk.download('wordnet')

# Text cleaning function definitions
def remove_html(text):
    """Remove HTML tags using a regex."""
    html = re.compile(r'<.*?>')
    return html.sub(r'', text)
def remove_emoji(text):
    """Remove emojis using a regex pattern."""
    emoji_pattern = re.compile("["
                               u"\U0001F600-\U0001F64F"  # emoticons
                               u"\U0001F300-\U0001F5FF"  # symbols & pictographs
                               u"\U0001F680-\U0001F6FF"  # transport & map symbols
                               u"\U0001F1E0-\U0001F1FF"  # flags
                               u"\U00002702-\U000027B0"
                               u"\U000024C2-\U0001F251"  # enclosed characters
                               "]+", flags=re.UNICODE)
    return emoji_pattern.sub(r'', text)
# Configuration parameters
input_path = '/content/ISE-solution/lab1/datasets/pytorch.csv'
output_dir = '/content/ISE-solution/lab1/results'
os.makedirs(output_dir, exist_ok=True)
output_file = os.path.join(output_dir, 'pytorch_improved.csv')
# Advanced text preprocessing
def advanced_cleaning(text):
    lemmatizer = WordNetLemmatizer()
    text = remove_html(text)
    text = remove_emoji(text)
    text = text.lower()
    text = re.sub(r'[^a-z0-9\s]', '', text)
    words = text.split()
    words = [lemmatizer.lemmatize(word) for word in words if word not in final_stop_words_list]
    return ' '.join(words)
# Load data
df = pd.read_csv(input_path)
df = df.sample(frac=1, random_state=42)
df['combined_text'] = df['Title'] + '. ' + df['Body'].fillna('')
# Data preprocessing
final_stop_words_list = stopwords.words('english') + ['...', 'pytorch', 'model', 'layer']
df['clean_text'] = df['combined_text'].apply(advanced_cleaning)
# Split dataset
X = df['clean_text']
y = df['class']
# Define models and parameter grids
models = {
    'LogisticRegression': {
        'model': LogisticRegression(max_iter=1000),
        'params': [
            {
                'penalty': ['l2'],
                'C': [0.1, 1, 10],
                'class_weight': ['balanced', None]
            },
            {
                'penalty': [None],
                'class_weight': ['balanced', None]
            }
        ]
    },
    'SVM': {
        'model': SVC(probability=True),
        'params': {
            'C': [0.1, 1, 10],
            'kernel': ['linear', 'rbf'],
            'gamma': ['scale', 'auto']
        }
    },
    'RandomForest': {
        'model': RandomForestClassifier(),
        'params': {
            'n_estimators': [100, 200],
            'max_depth': [None, 10, 20],
            'min_samples_split': [2, 5]
        }
    },
    'GradientBoosting': {
        'model': GradientBoostingClassifier(),
        'params': {
            'learning_rate': [0.1, 0.01],
            'n_estimators': [100, 200],
            'max_depth': [3, 5]
        }
    },
    'MultinomialNB': {
        'model': MultinomialNB(),
        'params': {
            'alpha': [0.1, 1, 10],
            'fit_prior': [True, False]
        }
    }
}
# Results container
results = defaultdict(list)
# Multiple experiment configuration
REPEAT = 30
kf = KFold(n_splits=5, shuffle=True, random_state=42)
for model_name, config in models.items():
    # Initialize temporary metric lists for each model
    acc_scores = []
    prec_scores = []
    rec_scores = []
    f1_scores = []
    auc_scores = []
    cv_scores = []
    for _ in range(REPEAT):
        # Data splitting
        train_idx, test_idx = next(kf.split(X))
        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]
        # Feature engineering
        tfidf = TfidfVectorizer(
            ngram_range=(1, 3),
            max_features=5000,
            stop_words=final_stop_words_list
        )
        X_train_tfidf = tfidf.fit_transform(X_train)
        X_test_tfidf = tfidf.transform(X_test)
        # Handle class imbalance
        sm = SMOTE(random_state=42)
        X_train_res, y_train_res = sm.fit_resample(X_train_tfidf, y_train)
        # Grid search
        grid = GridSearchCV(
            config['model'],
            config['params'],
            cv=3,
            scoring='roc_auc',
            n_jobs=-1
        )
        grid.fit(X_train_res, y_train_res)
        # Best model prediction
        best_clf = grid.best_estimator_
        y_pred = best_clf.predict(X_test_tfidf)
        y_proba = best_clf.predict_proba(X_test_tfidf)[:, 1]
        # Calculate metrics
        acc = accuracy_score(y_test, y_pred)
        prec = precision_score(y_test, y_pred, average='macro')
        rec = recall_score(y_test, y_pred, average='macro')
        f1 = f1_score(y_test, y_pred, average='macro')
        auc = roc_auc_score(y_test, y_proba)
        # Append metrics of each experiment to temporary lists
        acc_scores.append(acc)
        prec_scores.append(prec)
        rec_scores.append(rec)
        f1_scores.append(f1)
        auc_scores.append(auc)
        cv_scores.extend(grid.cv_results_['mean_test_score'])
    # Calculate the mean of each metric for each model
    results['Model'].append(model_name)
    results['repeated_times'].append(REPEAT)
    results['Accuracy'].append(np.mean(acc_scores))
    results['Precision'].append(np.mean(prec_scores))
    results['Recall'].append(np.mean(rec_scores))
    results['F1'].append(np.mean(f1_scores))
    results['AUC'].append(np.mean(auc_scores))
    results['CV_list(AUC)'].append(str(np.mean(cv_scores)))
# Save results
final_df = pd.DataFrame(results)
final_df.to_csv(output_file, index=False)
print(f"Optimized results saved to: {output_file}")
print(final_df.describe())